roxygen2::roxygenise("~/Documents/Github/googletraffic")
# Download Google Traffic Data from AWS
# Setup ------------------------------------------------------------------------
# Set AWS Keys
Sys.setenv("AWS_ACCESS_KEY_ID" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_ACCESS_KEY_ID")],
"AWS_SECRET_ACCESS_KEY" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_SECRET_ACCESS_KEY")],
"AWS_DEFAULT_REGION" = "us-east-2")
# Download Data ----------------------------------------------------------------
#### Load grid
grid_df <- readRDS(file.path(google_traffic_dir, "RawData", "nairobi_grid.Rds"))
#### Grab file names
s3_files <- get_bucket(bucket="wb-dime-googletraffic", max=Inf, url_style="path", prefix="nairobi_png/")
get_s3_keys <- function(i, s3_files) s3_files[i]$Contents$Key
s3_keys <- lapply(1:length(s3_files), get_s3_keys, s3_files) %>% unlist
s3_keys <- s3_keys[!endsWith(s3_keys, "/")]
s3_keys <- paste0("wb-dime-googletraffic/", s3_keys)
#### Grab time stamps
time_stamps <- s3_keys %>%
str_replace_all(".*_utc", "") %>%
str_replace_all("_id.*", "") %>%
unique()
for(time_stamp_i in time_stamps){
s3_keys_time_i <- s3_keys %>% str_subset(time_stamp_i)
out_path_rds <- file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds"))
if(!file.exists(out_path_rds)){
r_list <- lapply(s3_keys_time_i, function(s3_key_i){
print(paste0("Processing: ", s3_key_i))
id_i <- s3_key_i %>%
str_replace_all(".*_", "") %>%
str_replace_all(".png|id", "") %>%
as.numeric()
param_i <- grid_df[grid_df$id %in% id_i,]
r_i <- aws.s3::s3read_using(gt_load_png_as_traffic_raster,
object = paste0("s3://",s3_key_i),
latitude = param_i$latitude,
longitude = param_i$longitude,
height = param_i$height,
width = param_i$width,
zoom = param_i$zoom)
return(r_i)
})
## Mosaic individual rasters together
names(r_list)    <- NULL
#r_list$fun       <- max
r_list$tolerance <- 999
r_all <- do.call(raster::merge, r_list)
## Export
#saveRDS(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds")))
writeRaster(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".tiff")),
overwrite = T)
}
}
# r <- r_list[[8]]
# r[][is.na(r[])] <- 0
# pal <- colorNumeric(c("#0C2C84", "#41B6C4", "#FFFFCC"), values(r),
#                     na.color = "transparent")
#
# leaflet() %>% addTiles() %>%
#   addRasterImage(r, colors = pal, opacity = 0.8) %>%
#   addLegend(pal = pal, values = values(r),
#             title = "Surface temp")
# smarTTrans Master
Sys.setlocale("LC_ALL", "C")
# Root Filepaths ---------------------------------------------------------------
#### Main Project Root Paths
if(Sys.info()[["user"]] == "robmarty"){
dropbox_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
github_file_path <- "~/Documents/Github/CrashMap-Nairobi"
eCrash_system <- "~/Documents/Github/Kenya-Police-Dashboard"
tweet_algorithm_path <- "~/Documents/Github/Unique-Location-Extractor"
overleaf_file_path <- "~/Dropbox/Apps/Overleaf"
}
if(Sys.info()[["user"]] == "WB521633"){
dropbox_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
github_file_path <- "C:/Users/wb521633/Documents/Github/CrashMap-Nairobi"
onedrive_file_path <- "C:/Users/wb521633/OneDrive - WBG/smarTTrans"
eCrash_system <- "C:/Users/wb521633/OneDrive - WBG/Documents/Github/Kenya-Police-Dashboard"
tweet_algorithm_path <- "C:/Users/wb521633/OneDrive - WBG/Documents/Github/Unique-Location-Extractor"
}
if(Sys.info()[["user"]] == "ruiwenzhang"){
dropbox_file_path <- "~/Dropbox/CrashMap-Nairobi"
github_file_path <- "~/Documents/Github/CrashMap-Nairobi"
#onedrive_file_path <- "C:/Users/wb521633/OneDrive - WBG/smarTTrans"
#eCrash_system <- "C:/Users/wb521633/OneDrive - WBG/Documents/Github/Kenya-Police-Dashboard"
#tweet_algorithm_path <- "C:/Users/wb521633/OneDrive - WBG/Documents/Github/Unique-Location-Extractor"
}
#### Compatibility
# Some scripts user earlier versions of filenames. To ensure those work before
# update, add here
project_file_path <- dropbox_file_path
# Other Filepaths --------------------------------------------------------------
## Data Paths
# From Data/
data_dir               <- file.path(project_file_path, "Data")
gadm_dir               <- file.path(data_dir, "GADM")
google_street_view_dir <- file.path(data_dir, "Google Street View")
sendy_dir              <- file.path(data_dir, "Sendy")
blackspot_survey_dir   <- file.path(data_dir, "Blackspot Survey")
hist_rd_inf_policy_dir <- file.path(data_dir, "Historic Road Infrastructure and Policies")
keboundaryiebc         <- file.path(data_dir, "KEBoundaries-IEBC")
police_dir             <- file.path(data_dir, "Police Data")
police_allcrash_dir    <- file.path(data_dir, "Police Data", "Crash Report Data", "All Reports")
waze_dir               <- file.path(data_dir, "Waze")
flare_dir              <- file.path(data_dir, "Flare")
google_mobility_dir    <- file.path(data_dir, "Google Mobility Reports")
outlogic_dir           <- file.path(data_dir, "Outlogic")
uber_dir               <- file.path(data_dir, "Uber")
census_dir             <- file.path(data_dir, "Census")
mapbox_movement_dir    <- file.path(data_dir, "Mapbox Movement")
wards_dir              <- file.path(data_dir, "Kenya Wards")
google_basemaps_dir    <- file.path(data_dir, "Google Maps Basemaps")
kura_roads_dir         <- file.path(data_dir, "KURA", "KURA Road Shapefiles")
kura_cctv_dir          <- file.path(data_dir, "KURA", "CCTV")
kura_phase_dir         <- file.path(data_dir, "KURA", "KURA Phased Cameras and Improvements")
kura_traffic_vlm_dir   <- file.path(data_dir, "KURA", "Traffic Volume")
kura_cctv_locs_dir     <- file.path(data_dir, "KURA", "KURA Locations with CCTV")
krb_ric_dir            <- file.path(data_dir, "KRB", "Road Inventory and Condition - RIC")
google_traffic_dir     <- file.path(data_dir, "Google Traffic")
# From: Analysis, Papers, Briefs and Notes/
papernotes_dir  <- file.path(project_file_path, "Analysis, Papers, Briefs and Notes")
blackspots_ie   <- file.path(papernotes_dir, "Blackspots IE")
# From: Prep Data for External Organizations
data_ext_org_dir <- file.path(project_file_path, "Prep Data for External Organizations")
## Code Paths
project_git_path <- file.path(github_file_path)
datawork_git_path <- file.path(project_git_path, "DataWork")
dashboards_git_path <- file.path(project_git_path, "Dashboards")
## Other
#algorithm_inputs <- file.path(project_file_path, "Data", "FinalData", "Twitter Algorithm Inputs")
#tables_file_path <- file.path(project_file_path, "Outputs", "Papers", "Algorithm", "Tables")
#figures_file_path <- file.path(project_file_path, "Papers", "Algorithm", "Figures")
#outputs_file_path <- file.path(project_file_path, "Outputs")
# API Keys ---------------------------------------------------------------------
if(Sys.info()[["user"]] == "robmarty"){
api_keys_df <- read.csv(file.path("~/Dropbox", "World Bank", "Webscraping", "Files for Server", "api_keys.csv"),
stringsAsFactors = F)
}
if(Sys.info()[["user"]] == "WB521633"){
api_keys_df <- read.csv(file.path("C:/Users/wb521633/Dropbox/", "World Bank", "Webscraping", "Files for Server", "api_keys.csv"),
stringsAsFactors = F)
}
# Parameters -------------------------------------------------------------------
NAIROBI_UTM_PROJ <- "+init=epsg:21037"
# Packages ---------------------------------------------------------------------
library(gglasso)
library(glmnet)
library(gt)
library(leaflet)
library(jcolors)
library(googlesheets4)
library(labelled)
library(dplyr)
library(sparklyr)
library(geojsonio)
library(hrbrthemes)
library(ClusterR)
library(adehabitatHR)
library(tidyr)
library(rgdal)
library(DT)
library(rgeos)
library(openssl)
library(knitr)
library(data.table)
library(glmnet)
library(reshape)
library(fastDummies)
library(tidyr)
library(geosphere)
library(lubridate)
library(reshape)
library(raster)
library(rgdal)
library(dplyr)
library(readr)
library(quanteda)
library(quanteda.classifiers)
library(stringr)
library(stringi)
library(rgeos)
library(doBy)
library(hunspell)
library(ggplot2)
library(raster)
library(sp)
library(sf)
library(spdep)
library(mapview)
library(tools)
library(broom)
library(spatialEco)
library(RColorBrewer)
library(circular)
library(ggmapstyles) # devtools::install_github("dr-harper/ggmapstyles")
library(parallel)
library(pbmcapply)
library(stringr)
library(readxl)
library(doBy)
library(purrr)
library(ggmap)
library(grid)
library(gridExtra)
library(gtable)
library(scales)
library(tidyr)
library(ggpubr)
#library(wesanderson)
#library(jcolors)
library(readr)
library(htmlwidgets)
library(htmltools)
library(smoothr)
library(stringdist)
library(stringr)
library(quanteda)
library(caret)
library(bcrypt)
library(osrm)
library(parallel)
library(dplyr)
library(rdrop2)
library(readxl)
library(stringr)
library(haven)
library(readxl)
library(pbmcapply)
library(tidyr)
library(stringr)
library(ggrepel)
library(ggthemes)
library(googleway)
library(googledrive)
library(writexl)
library(dplyr)
library(lubridate)
library(parallel)
library(pbmcapply)
library(tidyr)
library(stringr)
library(googledrive)
library(devtools)
library(pdftools)
library(jpeg)
library(xlsx)
library(dismo)
library(stargazer)
library(MASS)
library(deldir)
library(LearnGeom)
library(lfe)
library(dplyr)
library(stringr)
library(ngram)
library(stringdist)
library(exactextractr)
library(glmnet)
library(quanteda.textmodels) # devtools::install_github("quanteda/quanteda.svm")
library(geosphere)
library(googlesheets)
library(ggplot2)
library(lubridate)
library(tidyverse)
library(googlesheets4)
library(arrow)
#library(Rcpp)
#library(tesseract)
library(dtplyr)
library(dplyr)
library(bdscale)
library(googleway)
library(htmlwidgets)
library(webshot)
library(raster)
library(png)
library(plotwidgets)
library(httr)
library(googletraffic)
#devtools::install_github("skgrange/gissr")
source("https://raw.githubusercontent.com/ramarty/Unique-Location-Extractor/master/R/load_ulex.R")
source(file.path(github_file_path, "Functions and Packages", "Tweet Classification", "tweet_classification.R"))
source(file.path(github_file_path, "Functions and Packages", "Clustering", "cluster_crashes_into_clusters.R"))
source(file.path(github_file_path, "Functions and Packages", "Clustering", "cluster_crashes_into_unique_crashes.R"))
source(file.path(github_file_path, "Functions and Packages", "commonly_used_functions.R"))
source("https://raw.githubusercontent.com/ramarty/fast-functions/master/R/functions_in_chunks.R")
source("https://raw.githubusercontent.com/ramarty/Waze/master/append_waze_from_s3.r")
# For downloading Waze Data
#source("https://raw.githubusercontent.com/worldbank/Data-Collaboratives/waze/r/Code/append_waze_from_s3.r?token=ACYONTQSWBR4FCSYELW2CVS7CGR7Y")
#source("https://raw.githubusercontent.com/worldbank/Data-Collaboratives/waze/r/Code/append_waze_from_s3.r?token=ACYONTVICRXERUR7GIK6F2C6QZYUY")
# Download Google Traffic Data from AWS
# Setup ------------------------------------------------------------------------
# Set AWS Keys
Sys.setenv("AWS_ACCESS_KEY_ID" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_ACCESS_KEY_ID")],
"AWS_SECRET_ACCESS_KEY" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_SECRET_ACCESS_KEY")],
"AWS_DEFAULT_REGION" = "us-east-2")
# Download Data ----------------------------------------------------------------
#### Load grid
grid_df <- readRDS(file.path(google_traffic_dir, "RawData", "nairobi_grid.Rds"))
#### Grab file names
s3_files <- get_bucket(bucket="wb-dime-googletraffic", max=Inf, url_style="path", prefix="nairobi_png/")
get_s3_keys <- function(i, s3_files) s3_files[i]$Contents$Key
s3_keys <- lapply(1:length(s3_files), get_s3_keys, s3_files) %>% unlist
s3_keys <- s3_keys[!endsWith(s3_keys, "/")]
s3_keys <- paste0("wb-dime-googletraffic/", s3_keys)
#### Grab time stamps
time_stamps <- s3_keys %>%
str_replace_all(".*_utc", "") %>%
str_replace_all("_id.*", "") %>%
unique()
for(time_stamp_i in time_stamps){
s3_keys_time_i <- s3_keys %>% str_subset(time_stamp_i)
out_path_rds <- file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds"))
if(!file.exists(out_path_rds)){
r_list <- lapply(s3_keys_time_i, function(s3_key_i){
print(paste0("Processing: ", s3_key_i))
id_i <- s3_key_i %>%
str_replace_all(".*_", "") %>%
str_replace_all(".png|id", "") %>%
as.numeric()
param_i <- grid_df[grid_df$id %in% id_i,]
r_i <- aws.s3::s3read_using(gt_load_png_as_traffic_raster,
object = paste0("s3://",s3_key_i),
latitude = param_i$latitude,
longitude = param_i$longitude,
height = param_i$height,
width = param_i$width,
zoom = param_i$zoom)
return(r_i)
})
## Mosaic individual rasters together
names(r_list)    <- NULL
#r_list$fun       <- max
r_list$tolerance <- 999
r_all <- do.call(raster::merge, r_list)
## Export
#saveRDS(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds")))
writeRaster(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".tiff")),
overwrite = T)
}
}
# r <- r_list[[8]]
# r[][is.na(r[])] <- 0
# pal <- colorNumeric(c("#0C2C84", "#41B6C4", "#FFFFCC"), values(r),
#                     na.color = "transparent")
#
# leaflet() %>% addTiles() %>%
#   addRasterImage(r, colors = pal, opacity = 0.8) %>%
#   addLegend(pal = pal, values = values(r),
#             title = "Surface temp")
# Download Google Traffic Data from AWS
# Setup ------------------------------------------------------------------------
# Set AWS Keys
Sys.setenv("AWS_ACCESS_KEY_ID" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_ACCESS_KEY_ID")],
"AWS_SECRET_ACCESS_KEY" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_SECRET_ACCESS_KEY")],
"AWS_DEFAULT_REGION" = "us-east-2")
# Download Data ----------------------------------------------------------------
#### Load grid
grid_df <- readRDS(file.path(google_traffic_dir, "RawData", "nairobi_grid.Rds"))
#### Grab file names
s3_files <- get_bucket(bucket="wb-dime-googletraffic", max=Inf, url_style="path", prefix="nairobi_png/")
get_s3_keys <- function(i, s3_files) s3_files[i]$Contents$Key
s3_keys <- lapply(1:length(s3_files), get_s3_keys, s3_files) %>% unlist
s3_keys <- s3_keys[!endsWith(s3_keys, "/")]
s3_keys <- paste0("wb-dime-googletraffic/", s3_keys)
#### Grab time stamps
time_stamps <- s3_keys %>%
str_replace_all(".*_utc", "") %>%
str_replace_all("_id.*", "") %>%
unique()
for(time_stamp_i in time_stamps){
s3_keys_time_i <- s3_keys %>% str_subset(time_stamp_i)
out_path_rds <- file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds"))
if(!file.exists(out_path_rds)){
r_list <- lapply(s3_keys_time_i, function(s3_key_i){
print(paste0("Processing: ", s3_key_i))
id_i <- s3_key_i %>%
str_replace_all(".*_", "") %>%
str_replace_all(".png|id", "") %>%
as.numeric()
param_i <- grid_df[grid_df$id %in% id_i,]
r_i <- aws.s3::s3read_using(gt_load_png_as_traffic_raster,
object = paste0("s3://",s3_key_i),
latitude = param_i$latitude,
longitude = param_i$longitude,
height = param_i$height,
width = param_i$width,
zoom = param_i$zoom)
return(r_i)
})
## Mosaic individual rasters together
names(r_list)    <- NULL
#r_list$fun       <- max
r_list$tolerance <- 999
r_all <- do.call(raster::merge, r_list)
## Export
#saveRDS(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds")))
writeRaster(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".tiff")),
overwrite = T)
}
}
# Setup ------------------------------------------------------------------------
library(raster)
git_dir <- "~/Documents/Github/googletraffic/R/"
source(file.path(git_dir, "gt_mosaic.R"))
source(file.path(git_dir,"gt_estimate_webshot_delay.R"))
source(file.path(git_dir,"gt_html_to_raster.R"))
source(file.path(git_dir,"gt_load_png_as_traffic_raster.R"))
source(file.path(git_dir,"gt_make_extent.R"))
source(file.path(git_dir,"gt_make_grid.R"))
source(file.path(git_dir,"gt_make_html.R"))
source(file.path(git_dir,"gt_make_png.R"))
source(file.path(git_dir,"gt_make_raster_from_grid.R"))
source(file.path(git_dir,"gt_make_raster_from_polygon.R"))
source(file.path(git_dir,"gt_make_raster.R"))
api_keys_df <- read.csv("~/Dropbox/World Bank/Webscraping/Files for Server/api_keys.csv")
google_key_df <- api_keys_df |>
dplyr::filter(Service == "Google Directions API",
Account == "ramarty@email.wm.edu")
google_key <- google_key_df$Key
google_key
# Make raster ------------------------------------------------------------------
r <- googletraffic::gt_make_raster(location = c(40.712778, -74.006111),
height     = 2000,
width      = 2000,
zoom       = 16,
webshot_delay = 20,
google_key = google_key)
r
plot(r)
# Make raster ------------------------------------------------------------------
r <- googletraffic::gt_make_raster(location = c(42.712778, -74.006111),
height     = 500,
width      = 500,
zoom       = 16,
webshot_delay = 20,
google_key = google_key)
plot(r)
r
